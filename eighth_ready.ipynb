{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程\n",
    "\n",
    "### 定义：\n",
    "\n",
    "Coming up with features is difficult, time-consuming, requires expert knowledge. \"Applied Machine Learning\" is basically feature enginnering.  ----Pro. Andrew Ng(吴恩达)\n",
    "\n",
    "Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in imporved model accuracy on unseen data.  ----Dr.Jason Brownlee\n",
    "\n",
    "数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。\n",
    "\n",
    "### 特征编码\n",
    "\n",
    "#### 1. 数值化数据\n",
    "\n",
    "将特征中的数据用数值代替，从而能够参与运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpple</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  class\n",
       "0  Facebook    one\n",
       "1    Google    two\n",
       "2   Twitter  three\n",
       "3    Alpple    one"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "students = pd.DataFrame({\"name\":[\"Facebook\", \"Google\", \"Twitter\", \"Alpple\"], 'class':['one', 'two', 'three', 'one']})\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "students['class'].replace({\"one\":1, \"two\":2, \"three\":3}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  class\n",
       "0  Facebook      1\n",
       "1    Google      2\n",
       "2   Twitter      3\n",
       "3    Alpple      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name     object\n",
       "class     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：数值化后，有的数据会出现了大小的比较，但事实上不一定各个数据之间有大小比较的意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newton</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Ng</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodan</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   color\n",
       "0      Newton   white\n",
       "1   Andrew Ng  yellow\n",
       "2       Jodan   black\n",
       "3  Bill Gates   white"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons = pd.DataFrame({\"name\":[\"Newton\", \"Andrew Ng\", \"Jodan\", \"Bill Gates\"], 'color':['white', 'yellow', 'black', 'white']})\n",
    "persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Ng</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  color\n",
       "0      Newton      1\n",
       "1   Andrew Ng      2\n",
       "2       Jodan      0\n",
       "3  Bill Gates      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons.replace({\"black\": 0, 'white': 1, 'yellow': 2})\n",
    "#这里不能认为数值就代表了任何顺序或者等级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Ng</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  color\n",
       "0      Newton      1\n",
       "1   Andrew Ng      2\n",
       "2       Jodan      0\n",
       "3  Bill Gates      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder    #利用LabelEncoder实现对具有类别的数据进行数值化编码\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(persons['color'])\n",
    "persons['color'] = labels\n",
    "persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上情况下，简单地数值化，显然不适合了，而persons里的数据，其实是分类数据，对于分类数据，通常采用的方式是二值化，或者说离散化。\n",
    "\n",
    "#### 2. 类别型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newton</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Ng</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodan</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   color\n",
       "0      Newton   white\n",
       "1   Andrew Ng  yellow\n",
       "2       Jodan   black\n",
       "3  Bill Gates   white"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   black  white  yellow\n",
       "0      0      1       0\n",
       "1      0      0       1\n",
       "2      1      0       0\n",
       "3      0      1       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dum = pd.get_dummies(persons['color'])   #创建哑变量dummy,虚拟变量\n",
    "df_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newton</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Ng</td>\n",
       "      <td>yellow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodan</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   color  black  white  yellow\n",
       "0      Newton   white      0      1       0\n",
       "1   Andrew Ng  yellow      0      0       1\n",
       "2       Jodan   black      1      0       0\n",
       "3  Bill Gates   white      0      1       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons.merge(df_dum, left_index=True, right_index=True)     #将两个DF合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上面的方式，将分类特征以1和0表示，是比较适合的。但是，我们可能会遇到一种情况，新建立的哑变量之间可能会有线性相关性。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men</td>\n",
       "      <td>zhang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>women</td>\n",
       "      <td>wang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>women</td>\n",
       "      <td>zhao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>men</td>\n",
       "      <td>qian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>women</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   name\n",
       "0    men  zhang\n",
       "1  women   wang\n",
       "2  women   zhao\n",
       "3    men   qian\n",
       "4  women    sun"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = pd.DataFrame({\"gender\": [\"men\", 'women', 'women', 'men', 'women'], 'name':[\"zhang\", 'wang', 'zhao', 'qian','sun']})\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>men</th>\n",
       "      <th>women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men</td>\n",
       "      <td>zhang</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>women</td>\n",
       "      <td>wang</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>women</td>\n",
       "      <td>zhao</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>men</td>\n",
       "      <td>qian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>women</td>\n",
       "      <td>sun</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   name  men  women\n",
       "0    men  zhang    1      0\n",
       "1  women   wang    0      1\n",
       "2  women   zhao    0      1\n",
       "3    men   qian    1      0\n",
       "4  women    sun    0      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([students, pd.get_dummies(students['gender'])], axis=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于以上结果，men或者women只要一列即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men</td>\n",
       "      <td>zhang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>women</td>\n",
       "      <td>wang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>women</td>\n",
       "      <td>zhao</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>men</td>\n",
       "      <td>qian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>women</td>\n",
       "      <td>sun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   name  women\n",
       "0    men  zhang      0\n",
       "1  women   wang      1\n",
       "2  women   zhao      1\n",
       "3    men   qian      0\n",
       "4  women    sun      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([students, pd.get_dummies(students['gender'], drop_first='True')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方式，称为one-hot编码。实现one-hot编码的方式，还有另外一种方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "features = ohe.fit_transform(students[['gender']])\n",
    "features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以实施one-hot编码的特征，通常是离散型的，也就是具有类别的数据。\n",
    "\n",
    "#### 3. 二值化\n",
    "\n",
    "与之类似的，还有一种被称为“二值化”的特征编码，它可以用来处理离散型特征，也可以用来处理连续型特征。\n",
    "\n",
    "二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0，公式表达如下：\n",
    "\n",
    "```\n",
    "    |1(x>threshold)\n",
    "x = | \n",
    "    |0(x<=threshold)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>CITY_ID</th>\n",
       "      <th>Exposed days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>146.272727</td>\n",
       "      <td>330.405303</td>\n",
       "      <td>108.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>83.933397</td>\n",
       "      <td>186.484137</td>\n",
       "      <td>58.626219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>73.750000</td>\n",
       "      <td>171.250000</td>\n",
       "      <td>64.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>144.500000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>220.250000</td>\n",
       "      <td>494.250000</td>\n",
       "      <td>144.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>286.000000</td>\n",
       "      <td>636.000000</td>\n",
       "      <td>279.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             RANK     CITY_ID  Exposed days\n",
       "count  264.000000  264.000000    264.000000\n",
       "mean   146.272727  330.405303    108.590909\n",
       "std     83.933397  186.484137     58.626219\n",
       "min      1.000000    1.000000      2.000000\n",
       "25%     73.750000  171.250000     64.750000\n",
       "50%    144.500000  340.000000     98.000000\n",
       "75%    220.250000  494.250000    144.250000\n",
       "max    286.000000  636.000000    279.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25 = pd.read_csv(\"/Users/qiwsir/Documents/Codes/DataSet/pm25/pm2.csv\")\n",
    "pm25.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>CITY_ID</th>\n",
       "      <th>CITY_NAME</th>\n",
       "      <th>Exposed days</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>268</td>\n",
       "      <td>381</td>\n",
       "      <td>南阳</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>229</td>\n",
       "      <td>242</td>\n",
       "      <td>淮南</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>520</td>\n",
       "      <td>海口</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>230</td>\n",
       "      <td>378</td>\n",
       "      <td>三门峡</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>227</td>\n",
       "      <td>441</td>\n",
       "      <td>常德</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>张家口</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>106</td>\n",
       "      <td>508</td>\n",
       "      <td>贵港</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>232</td>\n",
       "      <td>舟山</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>145</td>\n",
       "      <td>205</td>\n",
       "      <td>杭州</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>107</td>\n",
       "      <td>514</td>\n",
       "      <td>河池</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RANK  CITY_ID CITY_NAME  Exposed days  result\n",
       "245   268      381        南阳           203       1\n",
       "206   229      242        淮南           154       1\n",
       "18     20      520        海口            28       0\n",
       "207   230      378       三门峡           154       1\n",
       "204   227      441        常德           149       1\n",
       "47     55       23       张家口            52       0\n",
       "95    106      508        贵港            85       0\n",
       "25     28      232        舟山            34       0\n",
       "132   145      205        杭州            98       0\n",
       "96    107      514        河池            85       0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pm25['result'] = np.where(pm25[\"Exposed days\"] > pm25[\"Exposed days\"].mean(), 1, 0)\n",
    "pm25.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "bn = Binarizer(threshold=109)\n",
    "result = bn.fit_transform(pm25[[\"Exposed days\"]])   #注意，使用了列表作为下标，返回的是一个(n,1)的数组。\n",
    "pm25['result2'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>CITY_ID</th>\n",
       "      <th>CITY_NAME</th>\n",
       "      <th>Exposed days</th>\n",
       "      <th>result</th>\n",
       "      <th>result2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>172</td>\n",
       "      <td>189</td>\n",
       "      <td>盐城</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>175</td>\n",
       "      <td>137</td>\n",
       "      <td>哈尔滨</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>273</td>\n",
       "      <td>331</td>\n",
       "      <td>济宁</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>260</td>\n",
       "      <td>399</td>\n",
       "      <td>襄樊</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>276</td>\n",
       "      <td>351</td>\n",
       "      <td>菏泽</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>190</td>\n",
       "      <td>546</td>\n",
       "      <td>内江</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>259</td>\n",
       "      <td>388</td>\n",
       "      <td>驻马店</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>486</td>\n",
       "      <td>河源</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>164</td>\n",
       "      <td>178</td>\n",
       "      <td>苏州</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>62</td>\n",
       "      <td>44</td>\n",
       "      <td>朔州</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RANK  CITY_ID CITY_NAME  Exposed days  result  result2\n",
       "151   172      189        盐城           114       1        1\n",
       "153   175      137       哈尔滨           115       1        1\n",
       "250   273      331        济宁           211       1        1\n",
       "237   260      399        襄樊           196       1        1\n",
       "253   276      351        菏泽           221       1        1\n",
       "167   190      546        内江           124       1        1\n",
       "236   259      388       驻马店           196       1        1\n",
       "21     24      486        河源            31       0        0\n",
       "146   164      178        苏州           109       1        0\n",
       "54     62       44        朔州            58       0        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 生成多项式特征\n",
    "\n",
    "通常会给一定的特征数据进行分类或者回归预测。有时需要构建更多的特征，然后对特征再进行特征选择。通过增加一些输入数据的非线性特征来增加模型的复杂度通常是有效的。一个简单通用的办法是使用多项式特征，这可以获得特征的更高维度和互相间关系的项。\n",
    "\n",
    "例如：(x1, x2)，如果多项式最高项为2次，那么就转化为(1, x1, x2, x1^2, x1*x2, x2^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   2.04081633,   4.08163265,   6.12244898,\n",
       "         8.16326531,  10.20408163,  12.24489796,  14.28571429,\n",
       "        16.32653061,  18.36734694,  20.40816327,  22.44897959,\n",
       "        24.48979592,  26.53061224,  28.57142857,  30.6122449 ,\n",
       "        32.65306122,  34.69387755,  36.73469388,  38.7755102 ,\n",
       "        40.81632653,  42.85714286,  44.89795918,  46.93877551,\n",
       "        48.97959184,  51.02040816,  53.06122449,  55.10204082,\n",
       "        57.14285714,  59.18367347,  61.2244898 ,  63.26530612,\n",
       "        65.30612245,  67.34693878,  69.3877551 ,  71.42857143,\n",
       "        73.46938776,  75.51020408,  77.55102041,  79.59183673,\n",
       "        81.63265306,  83.67346939,  85.71428571,  87.75510204,\n",
       "        89.79591837,  91.83673469,  93.87755102,  95.91836735,\n",
       "        97.95918367, 100.        ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#应用，通过统计方法发现运动规律\n",
    "t = np.linspace(0, 100, 50)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.04081633e+01, 8.16326531e+01, 1.83673469e+02,\n",
       "       3.26530612e+02, 5.10204082e+02, 7.34693878e+02, 1.00000000e+03,\n",
       "       1.30612245e+03, 1.65306122e+03, 2.04081633e+03, 2.46938776e+03,\n",
       "       2.93877551e+03, 3.44897959e+03, 4.00000000e+03, 4.59183673e+03,\n",
       "       5.22448980e+03, 5.89795918e+03, 6.61224490e+03, 7.36734694e+03,\n",
       "       8.16326531e+03, 9.00000000e+03, 9.87755102e+03, 1.07959184e+04,\n",
       "       1.17551020e+04, 1.27551020e+04, 1.37959184e+04, 1.48775510e+04,\n",
       "       1.60000000e+04, 1.71632653e+04, 1.83673469e+04, 1.96122449e+04,\n",
       "       2.08979592e+04, 2.22244898e+04, 2.35918367e+04, 2.50000000e+04,\n",
       "       2.64489796e+04, 2.79387755e+04, 2.94693878e+04, 3.10408163e+04,\n",
       "       3.26530612e+04, 3.43061224e+04, 3.60000000e+04, 3.77346939e+04,\n",
       "       3.95102041e+04, 4.13265306e+04, 4.31836735e+04, 4.50816327e+04,\n",
       "       4.70204082e+04, 4.90000000e+04])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 4.9 * t*t\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.408163</td>\n",
       "      <td>2.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.632653</td>\n",
       "      <td>4.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.673469</td>\n",
       "      <td>6.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>326.530612</td>\n",
       "      <td>8.163265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            s         t\n",
       "0    0.000000  0.000000\n",
       "1   20.408163  2.040816\n",
       "2   81.632653  4.081633\n",
       "3  183.673469  6.122449\n",
       "4  326.530612  8.163265"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp = pd.DataFrame({\"s\":s, \"t\":t})    #寻找t和s之间的函数关系\n",
    "disp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x114b1f2b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(disp['t'], disp['s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.04081633e+00, 4.16493128e+00],\n",
       "       [1.00000000e+00, 4.08163265e+00, 1.66597251e+01],\n",
       "       [1.00000000e+00, 6.12244898e+00, 3.74843815e+01],\n",
       "       [1.00000000e+00, 8.16326531e+00, 6.66389005e+01],\n",
       "       [1.00000000e+00, 1.02040816e+01, 1.04123282e+02],\n",
       "       [1.00000000e+00, 1.22448980e+01, 1.49937526e+02],\n",
       "       [1.00000000e+00, 1.42857143e+01, 2.04081633e+02],\n",
       "       [1.00000000e+00, 1.63265306e+01, 2.66555602e+02],\n",
       "       [1.00000000e+00, 1.83673469e+01, 3.37359434e+02],\n",
       "       [1.00000000e+00, 2.04081633e+01, 4.16493128e+02],\n",
       "       [1.00000000e+00, 2.24489796e+01, 5.03956685e+02],\n",
       "       [1.00000000e+00, 2.44897959e+01, 5.99750104e+02],\n",
       "       [1.00000000e+00, 2.65306122e+01, 7.03873386e+02],\n",
       "       [1.00000000e+00, 2.85714286e+01, 8.16326531e+02],\n",
       "       [1.00000000e+00, 3.06122449e+01, 9.37109538e+02],\n",
       "       [1.00000000e+00, 3.26530612e+01, 1.06622241e+03],\n",
       "       [1.00000000e+00, 3.46938776e+01, 1.20366514e+03],\n",
       "       [1.00000000e+00, 3.67346939e+01, 1.34943773e+03],\n",
       "       [1.00000000e+00, 3.87755102e+01, 1.50354019e+03],\n",
       "       [1.00000000e+00, 4.08163265e+01, 1.66597251e+03],\n",
       "       [1.00000000e+00, 4.28571429e+01, 1.83673469e+03],\n",
       "       [1.00000000e+00, 4.48979592e+01, 2.01582674e+03],\n",
       "       [1.00000000e+00, 4.69387755e+01, 2.20324865e+03],\n",
       "       [1.00000000e+00, 4.89795918e+01, 2.39900042e+03],\n",
       "       [1.00000000e+00, 5.10204082e+01, 2.60308205e+03],\n",
       "       [1.00000000e+00, 5.30612245e+01, 2.81549354e+03],\n",
       "       [1.00000000e+00, 5.51020408e+01, 3.03623490e+03],\n",
       "       [1.00000000e+00, 5.71428571e+01, 3.26530612e+03],\n",
       "       [1.00000000e+00, 5.91836735e+01, 3.50270721e+03],\n",
       "       [1.00000000e+00, 6.12244898e+01, 3.74843815e+03],\n",
       "       [1.00000000e+00, 6.32653061e+01, 4.00249896e+03],\n",
       "       [1.00000000e+00, 6.53061224e+01, 4.26488963e+03],\n",
       "       [1.00000000e+00, 6.73469388e+01, 4.53561016e+03],\n",
       "       [1.00000000e+00, 6.93877551e+01, 4.81466056e+03],\n",
       "       [1.00000000e+00, 7.14285714e+01, 5.10204082e+03],\n",
       "       [1.00000000e+00, 7.34693878e+01, 5.39775094e+03],\n",
       "       [1.00000000e+00, 7.55102041e+01, 5.70179092e+03],\n",
       "       [1.00000000e+00, 7.75510204e+01, 6.01416077e+03],\n",
       "       [1.00000000e+00, 7.95918367e+01, 6.33486047e+03],\n",
       "       [1.00000000e+00, 8.16326531e+01, 6.66389005e+03],\n",
       "       [1.00000000e+00, 8.36734694e+01, 7.00124948e+03],\n",
       "       [1.00000000e+00, 8.57142857e+01, 7.34693878e+03],\n",
       "       [1.00000000e+00, 8.77551020e+01, 7.70095793e+03],\n",
       "       [1.00000000e+00, 8.97959184e+01, 8.06330696e+03],\n",
       "       [1.00000000e+00, 9.18367347e+01, 8.43398584e+03],\n",
       "       [1.00000000e+00, 9.38775510e+01, 8.81299459e+03],\n",
       "       [1.00000000e+00, 9.59183673e+01, 9.20033319e+03],\n",
       "       [1.00000000e+00, 9.79591837e+01, 9.59600167e+03],\n",
       "       [1.00000000e+00, 1.00000000e+02, 1.00000000e+04]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "t_poly = poly.fit_transform(disp[['t']])\n",
    "t_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.408163</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>4.164931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.632653</td>\n",
       "      <td>4.081633</td>\n",
       "      <td>16.659725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.673469</td>\n",
       "      <td>6.122449</td>\n",
       "      <td>37.484382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>326.530612</td>\n",
       "      <td>8.163265</td>\n",
       "      <td>66.638900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            s         t         t2\n",
       "0    0.000000  0.000000   0.000000\n",
       "1   20.408163  2.040816   4.164931\n",
       "2   81.632653  4.081633  16.659725\n",
       "3  183.673469  6.122449  37.484382\n",
       "4  326.530612  8.163265  66.638900"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp[\"t2\"] = t_poly[:, 2]\n",
    "disp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x114ce85f8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(disp['t2'], disp['s'])    #从图中可以看出，很明显的直线了。于是伟大的s=1/2 * g * t^2被发现了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 离散化\n",
    "离散化是数值型特征非常重要的一个处理，其实就是要将数值型数据转化成类别型数据\n",
    "\n",
    "连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理\n",
    "在工业界，很少直接将连续值作为特征喂给逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：\n",
    "\n",
    "- 稀疏向量内积乘法运算速度快，计算结果方便存储，容易scalable（扩展）。\n",
    "- 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。\n",
    "- Logistic回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。\n",
    "- 离散化后可以进行特征交叉，由M N个变量变为M*N个变量，进一步引入非线性，提升表达能力。\n",
    "- 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问。\n",
    "\n",
    "\n",
    "常用的离散化方法包括等值划分和等量划分。\n",
    "1. 等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1,2)，...，[9，10)。\n",
    "\n",
    "2. 等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Youth', 'Youth', 'Youth', 'Youth', 'Youth', 'Youth', 'YoungAdult',\n",
       "       'YoungAdult', 'Senior', 'MiddleAged', 'MiddleAged', 'YoungAdult'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = np.array([20, 22,25,27,21,23,37,31,61,45,41,32]) #一些年龄数据\n",
    "# 通过 pandas中的cut方法可以分割数据\n",
    "# factory = pd.cut(ages,4)     #arr原始数据 , 4：要分割成几段\n",
    "factory = pd.cut(ages,4,labels=['Youth', 'YoungAdult', 'MiddleAged', 'Senior']) #lable，对于每个类别可以自己命名\n",
    "# factory = pd.cut(arr,bins=[18,25,35,60,100],labels=['a','b','c','d']) #bins 自己指定的分割界限\n",
    "# factory.dtype  #CategoricalDtype，可以看到，cut后返回的是一个Categorical 类型的对象\n",
    "test = np.array(factory)  #获取出分类后的数据\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.999, 22.75]    3\n",
       "(22.75, 29.0]      3\n",
       "(29.0, 38.0]       3\n",
       "(38.0, 61.0]       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面看下等量划分\n",
    "# 通过 pandas中的qcut方法可以分割数据\n",
    "factory = pd.qcut(ages,4) \n",
    "# factory\n",
    "factory.value_counts()   #可以看到，通过等量划分，每个类别中的数据个数都一样\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本数据的特征工程\n",
    "\n",
    "在自然语言处理和文本分析的问题中，词袋（Bag of Words, BOW）和词向量（Word Embedding）是两种最常用的模型。\n",
    "\n",
    "#### 词袋\n",
    "\n",
    "假设一句文本，先进行分词，然后将这些词语作为一个集合，称之为“词袋”\n",
    "\n",
    "但是在算法中无法使用这些词汇，必须要将这些词数字化，即给每个词一个数字，这样词袋就编程了一些数字的集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"You raise me up You raise me up\", \n",
    "        \"so I can stand on mountains\",\n",
    "        \"You raise me up\", \n",
    "        \"to walk on stormy seas\",\n",
    "        \"I am strong\", \n",
    "        \"when I am on your shoulders\",\n",
    "        \"You raise me up\",\n",
    "        \"To more than I can be\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_data = vectorizer.fit_transform(text)\n",
    "train_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>be</th>\n",
       "      <th>can</th>\n",
       "      <th>me</th>\n",
       "      <th>more</th>\n",
       "      <th>mountains</th>\n",
       "      <th>on</th>\n",
       "      <th>raise</th>\n",
       "      <th>seas</th>\n",
       "      <th>shoulders</th>\n",
       "      <th>...</th>\n",
       "      <th>stand</th>\n",
       "      <th>stormy</th>\n",
       "      <th>strong</th>\n",
       "      <th>than</th>\n",
       "      <th>to</th>\n",
       "      <th>up</th>\n",
       "      <th>walk</th>\n",
       "      <th>when</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  be  can  me  more  mountains  on  raise  seas  shoulders  ...   stand  \\\n",
       "0   0   0    0   2     0          0   0      2     0          0  ...       0   \n",
       "1   0   0    1   0     0          1   1      0     0          0  ...       1   \n",
       "2   0   0    0   1     0          0   0      1     0          0  ...       0   \n",
       "3   0   0    0   0     0          0   1      0     1          0  ...       0   \n",
       "4   1   0    0   0     0          0   0      0     0          0  ...       0   \n",
       "5   1   0    0   0     0          0   1      0     0          1  ...       0   \n",
       "6   0   0    0   1     0          0   0      1     0          0  ...       0   \n",
       "7   0   1    1   0     1          0   0      0     0          0  ...       0   \n",
       "\n",
       "   stormy  strong  than  to  up  walk  when  you  your  \n",
       "0       0       0     0   0   2     0     0    2     0  \n",
       "1       0       0     0   0   0     0     0    0     0  \n",
       "2       0       0     0   0   1     0     0    1     0  \n",
       "3       1       0     0   1   0     1     0    0     0  \n",
       "4       0       1     0   0   0     0     0    0     0  \n",
       "5       0       0     0   0   0     0     1    0     1  \n",
       "6       0       0     0   0   1     0     0    1     0  \n",
       "7       0       0     1   1   0     0     0    0     0  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "pd.DataFrame(train_data.toarray(), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/gj/603w6p3505j5jp2sv_vl7lz40000gn/T/jieba.cache\n",
      "Loading model cost 1.047 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['国际 著名 综合类 科学 期刊 美国科学院 院刊 在线',\n",
       " '发表 了 苏州大学 数学 科学 学院 系统 生物学 研究 中心 马欢 飞 副教授 研究 课题组 的 课题',\n",
       " '马欢 飞 副教授 是 该 论文 第一 作者',\n",
       " '苏州大学 数学 科学 学院 是 唯一 第一 作者 单位',\n",
       " '这是 我校 首次 在 PNAS 发表 数学 类 论文']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#中文词袋，要先做分词\n",
    "text = ['国际著名综合类科学期刊美国科学院院刊在线', \n",
    "        '发表了苏州大学数学科学学院系统生物学研究中心马欢飞副教授研究课题组的课题',\n",
    "        '马欢飞副教授是该论文第一作者',\n",
    "        '苏州大学数学科学学院是唯一第一作者单位',\n",
    "        '这是我校首次在PNAS发表数学类论文']\n",
    "\n",
    "import jieba\n",
    "train_data = [\" \".join(jieba.cut(word)) for word in text]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnas</th>\n",
       "      <th>中心</th>\n",
       "      <th>作者</th>\n",
       "      <th>副教授</th>\n",
       "      <th>单位</th>\n",
       "      <th>发表</th>\n",
       "      <th>唯一</th>\n",
       "      <th>国际</th>\n",
       "      <th>在线</th>\n",
       "      <th>学院</th>\n",
       "      <th>...</th>\n",
       "      <th>美国科学院</th>\n",
       "      <th>苏州大学</th>\n",
       "      <th>著名</th>\n",
       "      <th>论文</th>\n",
       "      <th>课题</th>\n",
       "      <th>课题组</th>\n",
       "      <th>这是</th>\n",
       "      <th>院刊</th>\n",
       "      <th>首次</th>\n",
       "      <th>马欢</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pnas  中心  作者  副教授  单位  发表  唯一  国际  在线  学院 ...  美国科学院  苏州大学  著名  论文  课题  \\\n",
       "0     0   0   0    0   0   0   0   1   1   0 ...      1     0   1   0   0   \n",
       "1     0   1   0    1   0   1   0   0   0   1 ...      0     1   0   0   1   \n",
       "2     0   0   1    1   0   0   0   0   0   0 ...      0     0   0   1   0   \n",
       "3     0   0   1    0   1   0   1   0   0   1 ...      0     1   0   0   0   \n",
       "4     1   0   0    0   0   1   0   0   0   0 ...      0     0   0   1   0   \n",
       "\n",
       "   课题组  这是  院刊  首次  马欢  \n",
       "0    0   0   1   0   0  \n",
       "1    1   0   0   0   1  \n",
       "2    0   0   0   0   1  \n",
       "3    0   0   0   0   0  \n",
       "4    0   1   0   1   0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "train_counts = vect.fit_transform(train_data)\n",
    "words = vect.get_feature_names()\n",
    "pd.DataFrame(train_counts.toarray(), columns=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据词语的出现次数来构建词袋会出现一个问题：长的文章词语出现的次数会比短的文章要多，而实际上两篇文章可能谈论的都是同一个主题。\n",
    "\n",
    "于是乎，我们用tf（term frequencies）——单词出现次数除以文章总单词数——这样的方法来代替出现次数来构建词袋字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>be</th>\n",
       "      <th>can</th>\n",
       "      <th>me</th>\n",
       "      <th>more</th>\n",
       "      <th>mountains</th>\n",
       "      <th>on</th>\n",
       "      <th>raise</th>\n",
       "      <th>seas</th>\n",
       "      <th>shoulders</th>\n",
       "      <th>...</th>\n",
       "      <th>stand</th>\n",
       "      <th>stormy</th>\n",
       "      <th>strong</th>\n",
       "      <th>than</th>\n",
       "      <th>to</th>\n",
       "      <th>up</th>\n",
       "      <th>walk</th>\n",
       "      <th>when</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     am    be   can   me  more  mountains    on  raise  seas  shoulders  ...   \\\n",
       "0  0.00  0.00  0.00  0.5  0.00       0.00  0.00    0.5  0.00       0.00  ...    \n",
       "1  0.00  0.00  0.41  0.0  0.00       0.49  0.35    0.0  0.00       0.00  ...    \n",
       "2  0.00  0.00  0.00  0.5  0.00       0.00  0.00    0.5  0.00       0.00  ...    \n",
       "3  0.00  0.00  0.00  0.0  0.00       0.00  0.35    0.0  0.49       0.00  ...    \n",
       "4  0.64  0.00  0.00  0.0  0.00       0.00  0.00    0.0  0.00       0.00  ...    \n",
       "5  0.41  0.00  0.00  0.0  0.00       0.00  0.35    0.0  0.00       0.49  ...    \n",
       "6  0.00  0.00  0.00  0.5  0.00       0.00  0.00    0.5  0.00       0.00  ...    \n",
       "7  0.00  0.48  0.40  0.0  0.48       0.00  0.00    0.0  0.00       0.00  ...    \n",
       "\n",
       "   stand  stormy  strong  than    to   up  walk  when  you  your  \n",
       "0   0.00    0.00    0.00  0.00  0.00  0.5  0.00  0.00  0.5  0.00  \n",
       "1   0.49    0.00    0.00  0.00  0.00  0.0  0.00  0.00  0.0  0.00  \n",
       "2   0.00    0.00    0.00  0.00  0.00  0.5  0.00  0.00  0.5  0.00  \n",
       "3   0.00    0.49    0.00  0.00  0.41  0.0  0.49  0.00  0.0  0.00  \n",
       "4   0.00    0.00    0.77  0.00  0.00  0.0  0.00  0.00  0.0  0.00  \n",
       "5   0.00    0.00    0.00  0.00  0.00  0.0  0.00  0.49  0.0  0.49  \n",
       "6   0.00    0.00    0.00  0.00  0.00  0.5  0.00  0.00  0.5  0.00  \n",
       "7   0.00    0.00    0.00  0.48  0.40  0.0  0.00  0.00  0.0  0.00  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"You raise me up You raise me up\", \n",
    "        \"so I can stand on mountains\",\n",
    "        \"You raise me up\", \n",
    "        \"to walk on stormy seas\",\n",
    "        \"I am strong\", \n",
    "        \"when I am on your shoulders\",\n",
    "        \"You raise me up\",\n",
    "        \"To more than I can be\"]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1.)\n",
    "tv_array = tv.fit_transform(text).toarray()\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_array, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#示例\n",
    "#读取sklearn中的文本数据集\n",
    "#方法1\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法2\n",
    "from sklearn import datasets\n",
    "twenty_train = datasets.load_files(\"/Users/qiwsir/Documents/Codes/DataSet/20newsbydate/20news-bydate-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#显示分类名称\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => rec.autos\n"
     ]
    }
   ],
   "source": [
    "#使用朴素贝叶斯分类,并做出简单的预测\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "#进行训练的过程。 \n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target) \n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast'] \n",
    "X_new_counts = count_vect.transform(docs_new) \n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts) \n",
    "#重要的一行在这里，这是进行预测的过程。 \n",
    "predicted = clf.predict(X_new_tfidf) \n",
    "for doc, category in zip(docs_new, predicted): \n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词向量，英文名叫Word Embedding，按照字面意思，应该是词嵌入。\n",
    "\n",
    "Google的Word2Vec，关于它的介绍：\n",
    "\n",
    "Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n",
    "\n",
    "\n",
    "另外，用Keras之类的框架还有一个Embedding层，也说是将词ID映射为向量。\n",
    "\n",
    "由于先入为主的意识，大家可能就会将词向量跟Word2Vec等同起来，而反过来问“Embedding是哪种词向量？”这类问题，尤其是对于初学者来说，应该是很混淆的。\n",
    "\n",
    "### 时间类型的特征\n",
    "\n",
    "通常将时间转化为类别属性的特征\n",
    "\n",
    "- hour of the day (24 boolean features)\n",
    "- day of the week (7 boolean features)\n",
    "- day of the month (up to 31 boolean features)\n",
    "- month of the year (12 boolean features)\n",
    "- year (as many boolean features as they are different years in your dataset)\n",
    "\n",
    "可以把时间转换成连续值，也可以转换成离散值。\n",
    "\n",
    "- 连续值：比如持续时间（单页浏览时长），间隔时间（上次购买/点击离现在的时间）\n",
    "- 离散值：比如一天中哪个时间段(hour_0-23) ，一周中星期几(week_monday...) ，一年中哪个星期 ，工作日/周末 ， 一年中哪个季度 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自行车租赁数据\n",
    "bikes = pd.read_csv('/Users/qiwsir/Documents/Codes/DataSet/kaggle/bike_sharing_train.csv', header = 0, error_bad_lines=False)\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dateDays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-01-01 06:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-01 08:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-01-01 09:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011-01-01 10:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011-01-01 11:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2011-01-01 12:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2011-01-01 13:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2011-01-01 14:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2011-01-01 15:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011-01-01 16:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011-01-01 17:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011-01-01 18:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011-01-01 19:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011-01-01 20:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011-01-01 21:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2011-01-01 22:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2011-01-01 23:00:00</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2011-01-02 00:00:00</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2011-01-02 01:00:00</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2011-01-02 02:00:00</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2011-01-02 03:00:00</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2011-01-02 04:00:00</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2011-01-02 06:00:00</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10856</th>\n",
       "      <td>2012-12-18 18:00:00</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10857</th>\n",
       "      <td>2012-12-18 19:00:00</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>2012-12-18 20:00:00</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>2012-12-18 21:00:00</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>2012-12-18 22:00:00</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>2012-12-18 23:00:00</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>2012-12-19 00:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>2012-12-19 01:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864</th>\n",
       "      <td>2012-12-19 02:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10865</th>\n",
       "      <td>2012-12-19 03:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>2012-12-19 04:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>2012-12-19 05:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>2012-12-19 06:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>2012-12-19 07:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>2012-12-19 08:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>2012-12-19 09:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>2012-12-19 10:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>2012-12-19 11:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10874</th>\n",
       "      <td>2012-12-19 12:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10875</th>\n",
       "      <td>2012-12-19 13:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10876</th>\n",
       "      <td>2012-12-19 14:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>2012-12-19 15:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>2012-12-19 16:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>2012-12-19 17:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>2012-12-19 18:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>2012-12-19 19:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>2012-12-19 20:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>2012-12-19 21:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>2012-12-19 22:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>2012-12-19 23:00:00</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10886 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime        date      time  year  month  day  hour  \\\n",
       "0      2011-01-01 00:00:00  2011-01-01  00:00:00  2011      1    1     0   \n",
       "1      2011-01-01 01:00:00  2011-01-01  01:00:00  2011      1    1     1   \n",
       "2      2011-01-01 02:00:00  2011-01-01  02:00:00  2011      1    1     2   \n",
       "3      2011-01-01 03:00:00  2011-01-01  03:00:00  2011      1    1     3   \n",
       "4      2011-01-01 04:00:00  2011-01-01  04:00:00  2011      1    1     4   \n",
       "5      2011-01-01 05:00:00  2011-01-01  05:00:00  2011      1    1     5   \n",
       "6      2011-01-01 06:00:00  2011-01-01  06:00:00  2011      1    1     6   \n",
       "7      2011-01-01 07:00:00  2011-01-01  07:00:00  2011      1    1     7   \n",
       "8      2011-01-01 08:00:00  2011-01-01  08:00:00  2011      1    1     8   \n",
       "9      2011-01-01 09:00:00  2011-01-01  09:00:00  2011      1    1     9   \n",
       "10     2011-01-01 10:00:00  2011-01-01  10:00:00  2011      1    1    10   \n",
       "11     2011-01-01 11:00:00  2011-01-01  11:00:00  2011      1    1    11   \n",
       "12     2011-01-01 12:00:00  2011-01-01  12:00:00  2011      1    1    12   \n",
       "13     2011-01-01 13:00:00  2011-01-01  13:00:00  2011      1    1    13   \n",
       "14     2011-01-01 14:00:00  2011-01-01  14:00:00  2011      1    1    14   \n",
       "15     2011-01-01 15:00:00  2011-01-01  15:00:00  2011      1    1    15   \n",
       "16     2011-01-01 16:00:00  2011-01-01  16:00:00  2011      1    1    16   \n",
       "17     2011-01-01 17:00:00  2011-01-01  17:00:00  2011      1    1    17   \n",
       "18     2011-01-01 18:00:00  2011-01-01  18:00:00  2011      1    1    18   \n",
       "19     2011-01-01 19:00:00  2011-01-01  19:00:00  2011      1    1    19   \n",
       "20     2011-01-01 20:00:00  2011-01-01  20:00:00  2011      1    1    20   \n",
       "21     2011-01-01 21:00:00  2011-01-01  21:00:00  2011      1    1    21   \n",
       "22     2011-01-01 22:00:00  2011-01-01  22:00:00  2011      1    1    22   \n",
       "23     2011-01-01 23:00:00  2011-01-01  23:00:00  2011      1    1    23   \n",
       "24     2011-01-02 00:00:00  2011-01-02  00:00:00  2011      1    2     0   \n",
       "25     2011-01-02 01:00:00  2011-01-02  01:00:00  2011      1    2     1   \n",
       "26     2011-01-02 02:00:00  2011-01-02  02:00:00  2011      1    2     2   \n",
       "27     2011-01-02 03:00:00  2011-01-02  03:00:00  2011      1    2     3   \n",
       "28     2011-01-02 04:00:00  2011-01-02  04:00:00  2011      1    2     4   \n",
       "29     2011-01-02 06:00:00  2011-01-02  06:00:00  2011      1    2     6   \n",
       "...                    ...         ...       ...   ...    ...  ...   ...   \n",
       "10856  2012-12-18 18:00:00  2012-12-18  18:00:00  2012     12   18    18   \n",
       "10857  2012-12-18 19:00:00  2012-12-18  19:00:00  2012     12   18    19   \n",
       "10858  2012-12-18 20:00:00  2012-12-18  20:00:00  2012     12   18    20   \n",
       "10859  2012-12-18 21:00:00  2012-12-18  21:00:00  2012     12   18    21   \n",
       "10860  2012-12-18 22:00:00  2012-12-18  22:00:00  2012     12   18    22   \n",
       "10861  2012-12-18 23:00:00  2012-12-18  23:00:00  2012     12   18    23   \n",
       "10862  2012-12-19 00:00:00  2012-12-19  00:00:00  2012     12   19     0   \n",
       "10863  2012-12-19 01:00:00  2012-12-19  01:00:00  2012     12   19     1   \n",
       "10864  2012-12-19 02:00:00  2012-12-19  02:00:00  2012     12   19     2   \n",
       "10865  2012-12-19 03:00:00  2012-12-19  03:00:00  2012     12   19     3   \n",
       "10866  2012-12-19 04:00:00  2012-12-19  04:00:00  2012     12   19     4   \n",
       "10867  2012-12-19 05:00:00  2012-12-19  05:00:00  2012     12   19     5   \n",
       "10868  2012-12-19 06:00:00  2012-12-19  06:00:00  2012     12   19     6   \n",
       "10869  2012-12-19 07:00:00  2012-12-19  07:00:00  2012     12   19     7   \n",
       "10870  2012-12-19 08:00:00  2012-12-19  08:00:00  2012     12   19     8   \n",
       "10871  2012-12-19 09:00:00  2012-12-19  09:00:00  2012     12   19     9   \n",
       "10872  2012-12-19 10:00:00  2012-12-19  10:00:00  2012     12   19    10   \n",
       "10873  2012-12-19 11:00:00  2012-12-19  11:00:00  2012     12   19    11   \n",
       "10874  2012-12-19 12:00:00  2012-12-19  12:00:00  2012     12   19    12   \n",
       "10875  2012-12-19 13:00:00  2012-12-19  13:00:00  2012     12   19    13   \n",
       "10876  2012-12-19 14:00:00  2012-12-19  14:00:00  2012     12   19    14   \n",
       "10877  2012-12-19 15:00:00  2012-12-19  15:00:00  2012     12   19    15   \n",
       "10878  2012-12-19 16:00:00  2012-12-19  16:00:00  2012     12   19    16   \n",
       "10879  2012-12-19 17:00:00  2012-12-19  17:00:00  2012     12   19    17   \n",
       "10880  2012-12-19 18:00:00  2012-12-19  18:00:00  2012     12   19    18   \n",
       "10881  2012-12-19 19:00:00  2012-12-19  19:00:00  2012     12   19    19   \n",
       "10882  2012-12-19 20:00:00  2012-12-19  20:00:00  2012     12   19    20   \n",
       "10883  2012-12-19 21:00:00  2012-12-19  21:00:00  2012     12   19    21   \n",
       "10884  2012-12-19 22:00:00  2012-12-19  22:00:00  2012     12   19    22   \n",
       "10885  2012-12-19 23:00:00  2012-12-19  23:00:00  2012     12   19    23   \n",
       "\n",
       "       dayofweek  dateDays  \n",
       "0              5       0.0  \n",
       "1              5       0.0  \n",
       "2              5       0.0  \n",
       "3              5       0.0  \n",
       "4              5       0.0  \n",
       "5              5       0.0  \n",
       "6              5       0.0  \n",
       "7              5       0.0  \n",
       "8              5       0.0  \n",
       "9              5       0.0  \n",
       "10             5       0.0  \n",
       "11             5       0.0  \n",
       "12             5       0.0  \n",
       "13             5       0.0  \n",
       "14             5       0.0  \n",
       "15             5       0.0  \n",
       "16             5       0.0  \n",
       "17             5       0.0  \n",
       "18             5       0.0  \n",
       "19             5       0.0  \n",
       "20             5       0.0  \n",
       "21             5       0.0  \n",
       "22             5       0.0  \n",
       "23             5       0.0  \n",
       "24             6       1.0  \n",
       "25             6       1.0  \n",
       "26             6       1.0  \n",
       "27             6       1.0  \n",
       "28             6       1.0  \n",
       "29             6       1.0  \n",
       "...          ...       ...  \n",
       "10856          1     717.0  \n",
       "10857          1     717.0  \n",
       "10858          1     717.0  \n",
       "10859          1     717.0  \n",
       "10860          1     717.0  \n",
       "10861          1     717.0  \n",
       "10862          2     718.0  \n",
       "10863          2     718.0  \n",
       "10864          2     718.0  \n",
       "10865          2     718.0  \n",
       "10866          2     718.0  \n",
       "10867          2     718.0  \n",
       "10868          2     718.0  \n",
       "10869          2     718.0  \n",
       "10870          2     718.0  \n",
       "10871          2     718.0  \n",
       "10872          2     718.0  \n",
       "10873          2     718.0  \n",
       "10874          2     718.0  \n",
       "10875          2     718.0  \n",
       "10876          2     718.0  \n",
       "10877          2     718.0  \n",
       "10878          2     718.0  \n",
       "10879          2     718.0  \n",
       "10880          2     718.0  \n",
       "10881          2     718.0  \n",
       "10882          2     718.0  \n",
       "10883          2     718.0  \n",
       "10884          2     718.0  \n",
       "10885          2     718.0  \n",
       "\n",
       "[10886 rows x 9 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对特征datatime进行分解\n",
    "\n",
    "#data = bikes.iloc[:,:1]     #只看datatime这个属性\n",
    "daata = bikes.loc[:, (\"datetime\")]\n",
    "temp = pd.DatetimeIndex(data['datetime'])    #创建时间索引\n",
    "data['date'] = temp.date  #日期  \n",
    "data['time'] = temp.time  #时间\n",
    "data['year'] = temp.year  #年\n",
    "data['month'] = temp.month #月\n",
    "data['day'] = temp.day #日\n",
    "data['hour'] = temp.hour #小时\n",
    "data['dayofweek'] = temp.dayofweek  #具体星期几\n",
    "data['dateDays'] = (data.date - data.date[0]) #生成一个时间长度特征  ['0days','0days',...,'1days',...]\n",
    "data['dateDays'] = data['dateDays'].astype('timedelta64[D]')  #转换成float型\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征标准化\n",
    "\n",
    "#### 1. z-score标准化（标准差标准化）\n",
    "\n",
    "数据标准化是将样本的属性缩放到某个指定的范围，标准化的原因在于：\n",
    "\n",
    "- 某些算法要求数据具有零均值和单位方差。\n",
    "- 样本不同特征有不同的量级和单位。所有依赖于样本距离的算法（如KNN）对于数据的数量级都非常敏感。量级大的特征属性将占主导地位，且量级的差异会导致迭代速度减慢。为了消除量级的影响，必须进行数据标准化。\n",
    "\n",
    "标准化公式为： x_std = (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
       "        -9.20547742e-01],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
       "        -7.88915558e-01],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
       "         5.27406285e-01],\n",
       "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
       "         1.32509732e-01],\n",
       "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
       "         2.64141916e-01],\n",
       "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
       "         1.32509732e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
       "        -1.30754636e-01],\n",
       "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
       "        -1.30754636e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
       "        -2.62386821e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
       "         8.77547895e-04],\n",
       "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
       "         5.27406285e-01],\n",
       "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
       "         5.27406285e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
       "         1.32509732e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
       "         2.64141916e-01],\n",
       "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
       "        -1.30754636e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
       "         1.71209594e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
       "         1.18556721e+00],\n",
       "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
       "         1.18556721e+00],\n",
       "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         1.05393502e+00],\n",
       "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
       "         1.44883158e+00],\n",
       "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
       "         5.27406285e-01],\n",
       "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
       "         9.22302838e-01],\n",
       "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
       "         2.64141916e-01],\n",
       "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
       "         1.18556721e+00],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
       "         1.44883158e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
       "         7.90670654e-01]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "#标准化，返回值为标准化后的数据\n",
    "StandardScaler().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 区间缩放（Min-max 标准化，离差标准化）\n",
    "\n",
    "常见的一种为利用两个最值min、max进行缩放，\n",
    "\n",
    "公式：x2 = (x - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#区间缩放，返回值为缩放到[0, 1]区间的数据\n",
    "MinMaxScaler().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 归一化（正则化）\n",
    "\n",
    "将样本某个范数缩放到单位1，是针对单个样本的，对于每个样本将样本缩放到单位范数。其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
       "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ],\n",
       "       [0.78417499, 0.5663486 , 0.2468699 , 0.05808704],\n",
       "       [0.78010936, 0.57660257, 0.23742459, 0.0508767 ],\n",
       "       [0.80218492, 0.54548574, 0.24065548, 0.0320874 ],\n",
       "       [0.80642366, 0.5315065 , 0.25658935, 0.03665562],\n",
       "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
       "       [0.80373519, 0.55070744, 0.22325977, 0.02976797],\n",
       "       [0.786991  , 0.55745196, 0.26233033, 0.03279129],\n",
       "       [0.82307218, 0.51442011, 0.24006272, 0.01714734],\n",
       "       [0.8025126 , 0.55989251, 0.20529392, 0.01866308],\n",
       "       [0.81120865, 0.55945424, 0.16783627, 0.02797271],\n",
       "       [0.77381111, 0.59732787, 0.2036345 , 0.05430253],\n",
       "       [0.79428944, 0.57365349, 0.19121783, 0.05883625],\n",
       "       [0.80327412, 0.55126656, 0.22050662, 0.04725142],\n",
       "       [0.8068282 , 0.53788547, 0.24063297, 0.04246464],\n",
       "       [0.77964883, 0.58091482, 0.22930848, 0.0458617 ],\n",
       "       [0.8173379 , 0.51462016, 0.25731008, 0.03027177],\n",
       "       [0.78591858, 0.57017622, 0.23115252, 0.06164067],\n",
       "       [0.77577075, 0.60712493, 0.16864581, 0.03372916],\n",
       "       [0.80597792, 0.52151512, 0.26865931, 0.07901744],\n",
       "       [0.776114  , 0.54974742, 0.30721179, 0.03233808],\n",
       "       [0.82647451, 0.4958847 , 0.26447184, 0.03305898],\n",
       "       [0.79778206, 0.5424918 , 0.25529026, 0.06382256],\n",
       "       [0.80641965, 0.54278246, 0.23262105, 0.03101614],\n",
       "       [0.81609427, 0.5336001 , 0.21971769, 0.03138824],\n",
       "       [0.79524064, 0.54144043, 0.27072022, 0.03384003],\n",
       "       [0.80846584, 0.52213419, 0.26948861, 0.03368608],\n",
       "       [0.82225028, 0.51771314, 0.22840286, 0.06090743],\n",
       "       [0.76578311, 0.60379053, 0.22089897, 0.0147266 ],\n",
       "       [0.77867447, 0.59462414, 0.19820805, 0.02831544],\n",
       "       [0.81768942, 0.51731371, 0.25031309, 0.03337508],\n",
       "       [0.82512295, 0.52807869, 0.19802951, 0.03300492],\n",
       "       [0.82699754, 0.52627116, 0.19547215, 0.03007264],\n",
       "       [0.78523221, 0.5769053 , 0.22435206, 0.01602515],\n",
       "       [0.80212413, 0.54690282, 0.23699122, 0.03646019],\n",
       "       [0.80779568, 0.53853046, 0.23758697, 0.03167826],\n",
       "       [0.80033301, 0.56023311, 0.20808658, 0.04801998],\n",
       "       [0.86093857, 0.44003527, 0.24871559, 0.0573959 ],\n",
       "       [0.78609038, 0.57170209, 0.23225397, 0.03573138],\n",
       "       [0.78889479, 0.55222635, 0.25244633, 0.09466737],\n",
       "       [0.76693897, 0.57144472, 0.28572236, 0.06015208],\n",
       "       [0.82210585, 0.51381615, 0.23978087, 0.05138162],\n",
       "       [0.77729093, 0.57915795, 0.24385598, 0.030482  ],\n",
       "       [0.79594782, 0.55370283, 0.24224499, 0.03460643],\n",
       "       [0.79837025, 0.55735281, 0.22595384, 0.03012718],\n",
       "       [0.81228363, 0.5361072 , 0.22743942, 0.03249135],\n",
       "       [0.76701103, 0.35063361, 0.51499312, 0.15340221],\n",
       "       [0.74549757, 0.37274878, 0.52417798, 0.17472599],\n",
       "       [0.75519285, 0.33928954, 0.53629637, 0.16417236],\n",
       "       [0.75384916, 0.31524601, 0.54825394, 0.17818253],\n",
       "       [0.7581754 , 0.32659863, 0.5365549 , 0.17496355],\n",
       "       [0.72232962, 0.35482858, 0.57026022, 0.16474184],\n",
       "       [0.72634846, 0.38046824, 0.54187901, 0.18446945],\n",
       "       [0.75916547, 0.37183615, 0.51127471, 0.15493173],\n",
       "       [0.76301853, 0.33526572, 0.53180079, 0.15029153],\n",
       "       [0.72460233, 0.37623583, 0.54345175, 0.19508524],\n",
       "       [0.76923077, 0.30769231, 0.53846154, 0.15384615],\n",
       "       [0.73923462, 0.37588201, 0.52623481, 0.187941  ],\n",
       "       [0.78892752, 0.28927343, 0.52595168, 0.13148792],\n",
       "       [0.73081412, 0.34743622, 0.56308629, 0.16772783],\n",
       "       [0.75911707, 0.3931142 , 0.48800383, 0.17622361],\n",
       "       [0.76945444, 0.35601624, 0.50531337, 0.16078153],\n",
       "       [0.70631892, 0.37838513, 0.5675777 , 0.18919257],\n",
       "       [0.75676497, 0.35228714, 0.53495455, 0.13047672],\n",
       "       [0.76444238, 0.27125375, 0.55483721, 0.18494574],\n",
       "       [0.76185188, 0.34011245, 0.53057542, 0.14964948],\n",
       "       [0.6985796 , 0.37889063, 0.56833595, 0.21312598],\n",
       "       [0.77011854, 0.35349703, 0.50499576, 0.16412362],\n",
       "       [0.74143307, 0.29421947, 0.57667016, 0.17653168],\n",
       "       [0.73659895, 0.33811099, 0.56754345, 0.14490471],\n",
       "       [0.76741698, 0.34773582, 0.51560829, 0.15588157],\n",
       "       [0.76785726, 0.34902603, 0.51190484, 0.16287881],\n",
       "       [0.76467269, 0.31486523, 0.53976896, 0.15743261],\n",
       "       [0.74088576, 0.33173989, 0.55289982, 0.18798594],\n",
       "       [0.73350949, 0.35452959, 0.55013212, 0.18337737],\n",
       "       [0.78667474, 0.35883409, 0.48304589, 0.13801311],\n",
       "       [0.76521855, 0.33391355, 0.52869645, 0.15304371],\n",
       "       [0.77242925, 0.33706004, 0.51963422, 0.14044168],\n",
       "       [0.76434981, 0.35581802, 0.51395936, 0.15814134],\n",
       "       [0.70779525, 0.31850786, 0.60162596, 0.1887454 ],\n",
       "       [0.69333409, 0.38518561, 0.57777841, 0.1925928 ],\n",
       "       [0.71524936, 0.40530797, 0.53643702, 0.19073316],\n",
       "       [0.75457341, 0.34913098, 0.52932761, 0.16893434],\n",
       "       [0.77530021, 0.28304611, 0.54147951, 0.15998258],\n",
       "       [0.72992443, 0.39103094, 0.53440896, 0.16944674],\n",
       "       [0.74714194, 0.33960997, 0.54337595, 0.17659719],\n",
       "       [0.72337118, 0.34195729, 0.57869695, 0.15782644],\n",
       "       [0.73260391, 0.36029701, 0.55245541, 0.1681386 ],\n",
       "       [0.76262994, 0.34186859, 0.52595168, 0.1577855 ],\n",
       "       [0.76986879, 0.35413965, 0.5081134 , 0.15397376],\n",
       "       [0.73544284, 0.35458851, 0.55158213, 0.1707278 ],\n",
       "       [0.73239618, 0.38547167, 0.53966034, 0.15418867],\n",
       "       [0.73446047, 0.37367287, 0.5411814 , 0.16750853],\n",
       "       [0.75728103, 0.3542121 , 0.52521104, 0.15878473],\n",
       "       [0.78258054, 0.38361791, 0.4603415 , 0.16879188],\n",
       "       [0.7431482 , 0.36505526, 0.5345452 , 0.16948994],\n",
       "       [0.65387747, 0.34250725, 0.62274045, 0.25947519],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.71491405, 0.30207636, 0.59408351, 0.21145345],\n",
       "       [0.69276796, 0.31889319, 0.61579374, 0.1979337 ],\n",
       "       [0.68619022, 0.31670318, 0.61229281, 0.232249  ],\n",
       "       [0.70953708, 0.28008043, 0.61617694, 0.1960563 ],\n",
       "       [0.67054118, 0.34211284, 0.61580312, 0.23263673],\n",
       "       [0.71366557, 0.28351098, 0.61590317, 0.17597233],\n",
       "       [0.71414125, 0.26647062, 0.61821183, 0.19185884],\n",
       "       [0.69198788, 0.34599394, 0.58626751, 0.24027357],\n",
       "       [0.71562645, 0.3523084 , 0.56149152, 0.22019275],\n",
       "       [0.71576546, 0.30196356, 0.59274328, 0.21249287],\n",
       "       [0.71718148, 0.31640359, 0.58007326, 0.22148252],\n",
       "       [0.6925518 , 0.30375079, 0.60750157, 0.24300063],\n",
       "       [0.67767924, 0.32715549, 0.59589036, 0.28041899],\n",
       "       [0.69589887, 0.34794944, 0.57629125, 0.25008866],\n",
       "       [0.70610474, 0.3258945 , 0.59747324, 0.1955367 ],\n",
       "       [0.69299099, 0.34199555, 0.60299216, 0.19799743],\n",
       "       [0.70600618, 0.2383917 , 0.63265489, 0.21088496],\n",
       "       [0.72712585, 0.26661281, 0.60593821, 0.18178146],\n",
       "       [0.70558934, 0.32722984, 0.58287815, 0.23519645],\n",
       "       [0.68307923, 0.34153961, 0.59769433, 0.24395687],\n",
       "       [0.71486543, 0.25995106, 0.62202576, 0.18567933],\n",
       "       [0.73122464, 0.31338199, 0.56873028, 0.20892133],\n",
       "       [0.69595601, 0.3427843 , 0.59208198, 0.21813547],\n",
       "       [0.71529453, 0.31790868, 0.59607878, 0.17882363],\n",
       "       [0.72785195, 0.32870733, 0.56349829, 0.21131186],\n",
       "       [0.71171214, 0.35002236, 0.57170319, 0.21001342],\n",
       "       [0.69594002, 0.30447376, 0.60894751, 0.22835532],\n",
       "       [0.73089855, 0.30454106, 0.58877939, 0.1624219 ],\n",
       "       [0.72766159, 0.27533141, 0.59982915, 0.18683203],\n",
       "       [0.71578999, 0.34430405, 0.5798805 , 0.18121266],\n",
       "       [0.69417747, 0.30370264, 0.60740528, 0.2386235 ],\n",
       "       [0.72366005, 0.32162669, 0.58582004, 0.17230001],\n",
       "       [0.69385414, 0.29574111, 0.63698085, 0.15924521],\n",
       "       [0.73154399, 0.28501714, 0.57953485, 0.21851314],\n",
       "       [0.67017484, 0.36168166, 0.59571097, 0.2553047 ],\n",
       "       [0.69804799, 0.338117  , 0.59988499, 0.196326  ],\n",
       "       [0.71066905, 0.35533453, 0.56853524, 0.21320072],\n",
       "       [0.72415258, 0.32534391, 0.56672811, 0.22039426],\n",
       "       [0.69997037, 0.32386689, 0.58504986, 0.25073566],\n",
       "       [0.73337886, 0.32948905, 0.54206264, 0.24445962],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.69193502, 0.32561648, 0.60035539, 0.23403685],\n",
       "       [0.68914871, 0.33943145, 0.58629069, 0.25714504],\n",
       "       [0.72155725, 0.32308533, 0.56001458, 0.24769876],\n",
       "       [0.72965359, 0.28954508, 0.57909015, 0.22005426],\n",
       "       [0.71653899, 0.3307103 , 0.57323119, 0.22047353],\n",
       "       [0.67467072, 0.36998072, 0.58761643, 0.25028107],\n",
       "       [0.69025916, 0.35097923, 0.5966647 , 0.21058754]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer \n",
    "#归一化，返回值为归一化后的数据\n",
    "Normalizer().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler和Normalizer这个两个概念的问题(大家翻译上的误差导致信息非常混乱)，\n",
    "\n",
    "其实StandardScaler就是尺寸缩放问题，即使同一特征下的数值在一定范围内浮动，如将数值所放在0-1范围内(MinMaxScaler), 或者将数据标准化成为均值为0，方差为1的数据(Z-score)；\n",
    "\n",
    "Normalizer，将同一行数据的不同特征进行规范化，这样一个数据的不同特征具有相同的量纲或者表现力，比如说一个特征是身高，1.7m，体重为150斤，那么两个特征之间差距太大，身高这个特征变化根本无法起到决定作用(在体重这个变化特征下)，毕竟大家怎么长都是一米多，但是体重差距一下子拉开20多是很正常的事\n",
    "\n",
    "### 特征选择\n",
    "\n",
    "根据特征选择的形式又可以将特征选择方法分为3种：\n",
    "\n",
    "- Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "- Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。\n",
    "- Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。\n",
    "\n",
    "#### 1. 过滤法\n",
    "过滤法主要思想是：按照发散性或者相关性对各个特征进行对每一维的特征“打分”，即给每一维的特征赋予权重，这样的权重就代表着该维特征的重要性，设定阈值或者待选择阈值的个数，选择特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.1],\n",
       "       [1.2],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1.7],\n",
       "       [1.9],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.2],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.6],\n",
       "       [1.9],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [4.7],\n",
       "       [4.5],\n",
       "       [4.9],\n",
       "       [4. ],\n",
       "       [4.6],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [3.3],\n",
       "       [4.6],\n",
       "       [3.9],\n",
       "       [3.5],\n",
       "       [4.2],\n",
       "       [4. ],\n",
       "       [4.7],\n",
       "       [3.6],\n",
       "       [4.4],\n",
       "       [4.5],\n",
       "       [4.1],\n",
       "       [4.5],\n",
       "       [3.9],\n",
       "       [4.8],\n",
       "       [4. ],\n",
       "       [4.9],\n",
       "       [4.7],\n",
       "       [4.3],\n",
       "       [4.4],\n",
       "       [4.8],\n",
       "       [5. ],\n",
       "       [4.5],\n",
       "       [3.5],\n",
       "       [3.8],\n",
       "       [3.7],\n",
       "       [3.9],\n",
       "       [5.1],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [4.4],\n",
       "       [4.1],\n",
       "       [4. ],\n",
       "       [4.4],\n",
       "       [4.6],\n",
       "       [4. ],\n",
       "       [3.3],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.3],\n",
       "       [3. ],\n",
       "       [4.1],\n",
       "       [6. ],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.6],\n",
       "       [4.5],\n",
       "       [6.3],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [5. ],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [6.7],\n",
       "       [6.9],\n",
       "       [5. ],\n",
       "       [5.7],\n",
       "       [4.9],\n",
       "       [6.7],\n",
       "       [4.9],\n",
       "       [5.7],\n",
       "       [6. ],\n",
       "       [4.8],\n",
       "       [4.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [6.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.6],\n",
       "       [6.1],\n",
       "       [5.6],\n",
       "       [5.5],\n",
       "       [4.8],\n",
       "       [5.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.7],\n",
       "       [5.2],\n",
       "       [5. ],\n",
       "       [5.2],\n",
       "       [5.4],\n",
       "       [5.1]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 移除低方差的特征 (Removing features with low variance)\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "#方差选择法，返回值为特征选择后的数据 \n",
    "#参数threshold为方差的阈值 \n",
    "VarianceThreshold(threshold=3).fit_transform(iris.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 例子 ，比如第一列的特征，只有一个为1的，那这个特征几乎是无用的，可以砍掉 --- \n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]) \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=(0.8 * (1 - 0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单变量特征选择 (Univariate feature selection)\n",
    "\n",
    "单变量特征选择能够对每一个特征进行测试，衡量该特征和响应变量之间的关系，根据得分扔掉不好的特征。对于回归和分类问题可以采用卡方检验等方式对特征进行测试。\n",
    "\n",
    "方法简单，易于运行，易于理解，通常对于理解数据有较好的效果（但对特征优化、提高泛化能力来说不一定有效）；这种方法有许多改进的版本、变种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#卡方(Chi2)检验\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "#选择K个最好的特征，返回选择特征后的数据 \n",
    "SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 例子 --- \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "iris = load_iris() \n",
    "X, y = iris.data, iris.target \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower noise (0.7182483686213841, 7.32401731299835e-49)\n",
      "Higher noise (0.057964292079338155, 0.3170099388532475)\n"
     ]
    }
   ],
   "source": [
    "# Pearson相关系数 (Pearson Correlation),适用于：回归问题(y连续)\n",
    "import numpy as np \n",
    "from scipy.stats import pearsonr \n",
    "np.random.seed(0) \n",
    "size = 300 \n",
    "x = np.random.normal(0, 1, size) \n",
    "# pearsonr(x, y)的输入为特征矩阵和目标向量 \n",
    "# np.random.normal(0, 1, 100) 创建100个均值为0，方差为1的高斯随机数 \n",
    "print(\"Lower noise\", pearsonr(x, x + np.random.normal(0, 1, size))) \n",
    "print(\"Higher noise\", pearsonr(x, x + np.random.normal(0, 10, size))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其它方法：\n",
    "- 互信息和最大信息系数 (Mutual information and maximal information coefficient (MIC)\n",
    "- 距离相关系数 (Distance Correlation)\n",
    "\n",
    "#### 2 Wrapper（包装）\n",
    "\n",
    "包装法主要思想是：根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。也可以将特征子集的选择看作是一个搜索寻优问题，生成不同的组合，对组合进行评价，再与其他的组合进行比较。这样就将子集的选择看作是一个是一个优化问题，这里有很多的优化算法可以解决，尤其是一些启发式的优化算法，如GA，PSO，DE，ABC等，详见“优化算法—人工蜂群算法(ABC)”，“优化算法—粒子群算法(PSO)”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.5, 0.2],\n",
       "       [3. , 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.6, 0.2],\n",
       "       [3.9, 0.4],\n",
       "       [3.4, 0.3],\n",
       "       [3.4, 0.2],\n",
       "       [2.9, 0.2],\n",
       "       [3.1, 0.1],\n",
       "       [3.7, 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3. , 0.1],\n",
       "       [3. , 0.1],\n",
       "       [4. , 0.2],\n",
       "       [4.4, 0.4],\n",
       "       [3.9, 0.4],\n",
       "       [3.5, 0.3],\n",
       "       [3.8, 0.3],\n",
       "       [3.8, 0.3],\n",
       "       [3.4, 0.2],\n",
       "       [3.7, 0.4],\n",
       "       [3.6, 0.2],\n",
       "       [3.3, 0.5],\n",
       "       [3.4, 0.2],\n",
       "       [3. , 0.2],\n",
       "       [3.4, 0.4],\n",
       "       [3.5, 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.4, 0.4],\n",
       "       [4.1, 0.1],\n",
       "       [4.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.5, 0.2],\n",
       "       [3.6, 0.1],\n",
       "       [3. , 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3.5, 0.3],\n",
       "       [2.3, 0.3],\n",
       "       [3.2, 0.2],\n",
       "       [3.5, 0.6],\n",
       "       [3.8, 0.4],\n",
       "       [3. , 0.3],\n",
       "       [3.8, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.7, 0.2],\n",
       "       [3.3, 0.2],\n",
       "       [3.2, 1.4],\n",
       "       [3.2, 1.5],\n",
       "       [3.1, 1.5],\n",
       "       [2.3, 1.3],\n",
       "       [2.8, 1.5],\n",
       "       [2.8, 1.3],\n",
       "       [3.3, 1.6],\n",
       "       [2.4, 1. ],\n",
       "       [2.9, 1.3],\n",
       "       [2.7, 1.4],\n",
       "       [2. , 1. ],\n",
       "       [3. , 1.5],\n",
       "       [2.2, 1. ],\n",
       "       [2.9, 1.4],\n",
       "       [2.9, 1.3],\n",
       "       [3.1, 1.4],\n",
       "       [3. , 1.5],\n",
       "       [2.7, 1. ],\n",
       "       [2.2, 1.5],\n",
       "       [2.5, 1.1],\n",
       "       [3.2, 1.8],\n",
       "       [2.8, 1.3],\n",
       "       [2.5, 1.5],\n",
       "       [2.8, 1.2],\n",
       "       [2.9, 1.3],\n",
       "       [3. , 1.4],\n",
       "       [2.8, 1.4],\n",
       "       [3. , 1.7],\n",
       "       [2.9, 1.5],\n",
       "       [2.6, 1. ],\n",
       "       [2.4, 1.1],\n",
       "       [2.4, 1. ],\n",
       "       [2.7, 1.2],\n",
       "       [2.7, 1.6],\n",
       "       [3. , 1.5],\n",
       "       [3.4, 1.6],\n",
       "       [3.1, 1.5],\n",
       "       [2.3, 1.3],\n",
       "       [3. , 1.3],\n",
       "       [2.5, 1.3],\n",
       "       [2.6, 1.2],\n",
       "       [3. , 1.4],\n",
       "       [2.6, 1.2],\n",
       "       [2.3, 1. ],\n",
       "       [2.7, 1.3],\n",
       "       [3. , 1.2],\n",
       "       [2.9, 1.3],\n",
       "       [2.9, 1.3],\n",
       "       [2.5, 1.1],\n",
       "       [2.8, 1.3],\n",
       "       [3.3, 2.5],\n",
       "       [2.7, 1.9],\n",
       "       [3. , 2.1],\n",
       "       [2.9, 1.8],\n",
       "       [3. , 2.2],\n",
       "       [3. , 2.1],\n",
       "       [2.5, 1.7],\n",
       "       [2.9, 1.8],\n",
       "       [2.5, 1.8],\n",
       "       [3.6, 2.5],\n",
       "       [3.2, 2. ],\n",
       "       [2.7, 1.9],\n",
       "       [3. , 2.1],\n",
       "       [2.5, 2. ],\n",
       "       [2.8, 2.4],\n",
       "       [3.2, 2.3],\n",
       "       [3. , 1.8],\n",
       "       [3.8, 2.2],\n",
       "       [2.6, 2.3],\n",
       "       [2.2, 1.5],\n",
       "       [3.2, 2.3],\n",
       "       [2.8, 2. ],\n",
       "       [2.8, 2. ],\n",
       "       [2.7, 1.8],\n",
       "       [3.3, 2.1],\n",
       "       [3.2, 1.8],\n",
       "       [2.8, 1.8],\n",
       "       [3. , 1.8],\n",
       "       [2.8, 2.1],\n",
       "       [3. , 1.6],\n",
       "       [2.8, 1.9],\n",
       "       [3.8, 2. ],\n",
       "       [2.8, 2.2],\n",
       "       [2.8, 1.5],\n",
       "       [2.6, 1.4],\n",
       "       [3. , 2.3],\n",
       "       [3.4, 2.4],\n",
       "       [3.1, 1.8],\n",
       "       [3. , 1.8],\n",
       "       [3.1, 2.1],\n",
       "       [3.1, 2.4],\n",
       "       [3.1, 2.3],\n",
       "       [2.7, 1.9],\n",
       "       [3.2, 2.3],\n",
       "       [3.3, 2.5],\n",
       "       [3. , 2.3],\n",
       "       [2.5, 1.9],\n",
       "       [3. , 2. ],\n",
       "       [3.4, 2.3],\n",
       "       [3. , 1.8]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic特征消除法\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "#递归特征消除法，返回特征选择后的数据 \n",
    "#参数estimator为基模型 \n",
    "#参数n_features_to_select为选择的特征个数 \n",
    "RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Embedded（嵌入）\n",
    "\n",
    "嵌入法主要思想是：使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。其实是讲在确定模型的过程中，挑选出那些对模型的训练有重要意义的属性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4],\n",
       "       [4.9, 3. , 1.4],\n",
       "       [4.7, 3.2, 1.3],\n",
       "       [4.6, 3.1, 1.5],\n",
       "       [5. , 3.6, 1.4],\n",
       "       [5.4, 3.9, 1.7],\n",
       "       [4.6, 3.4, 1.4],\n",
       "       [5. , 3.4, 1.5],\n",
       "       [4.4, 2.9, 1.4],\n",
       "       [4.9, 3.1, 1.5],\n",
       "       [5.4, 3.7, 1.5],\n",
       "       [4.8, 3.4, 1.6],\n",
       "       [4.8, 3. , 1.4],\n",
       "       [4.3, 3. , 1.1],\n",
       "       [5.8, 4. , 1.2],\n",
       "       [5.7, 4.4, 1.5],\n",
       "       [5.4, 3.9, 1.3],\n",
       "       [5.1, 3.5, 1.4],\n",
       "       [5.7, 3.8, 1.7],\n",
       "       [5.1, 3.8, 1.5],\n",
       "       [5.4, 3.4, 1.7],\n",
       "       [5.1, 3.7, 1.5],\n",
       "       [4.6, 3.6, 1. ],\n",
       "       [5.1, 3.3, 1.7],\n",
       "       [4.8, 3.4, 1.9],\n",
       "       [5. , 3. , 1.6],\n",
       "       [5. , 3.4, 1.6],\n",
       "       [5.2, 3.5, 1.5],\n",
       "       [5.2, 3.4, 1.4],\n",
       "       [4.7, 3.2, 1.6],\n",
       "       [4.8, 3.1, 1.6],\n",
       "       [5.4, 3.4, 1.5],\n",
       "       [5.2, 4.1, 1.5],\n",
       "       [5.5, 4.2, 1.4],\n",
       "       [4.9, 3.1, 1.5],\n",
       "       [5. , 3.2, 1.2],\n",
       "       [5.5, 3.5, 1.3],\n",
       "       [4.9, 3.6, 1.4],\n",
       "       [4.4, 3. , 1.3],\n",
       "       [5.1, 3.4, 1.5],\n",
       "       [5. , 3.5, 1.3],\n",
       "       [4.5, 2.3, 1.3],\n",
       "       [4.4, 3.2, 1.3],\n",
       "       [5. , 3.5, 1.6],\n",
       "       [5.1, 3.8, 1.9],\n",
       "       [4.8, 3. , 1.4],\n",
       "       [5.1, 3.8, 1.6],\n",
       "       [4.6, 3.2, 1.4],\n",
       "       [5.3, 3.7, 1.5],\n",
       "       [5. , 3.3, 1.4],\n",
       "       [7. , 3.2, 4.7],\n",
       "       [6.4, 3.2, 4.5],\n",
       "       [6.9, 3.1, 4.9],\n",
       "       [5.5, 2.3, 4. ],\n",
       "       [6.5, 2.8, 4.6],\n",
       "       [5.7, 2.8, 4.5],\n",
       "       [6.3, 3.3, 4.7],\n",
       "       [4.9, 2.4, 3.3],\n",
       "       [6.6, 2.9, 4.6],\n",
       "       [5.2, 2.7, 3.9],\n",
       "       [5. , 2. , 3.5],\n",
       "       [5.9, 3. , 4.2],\n",
       "       [6. , 2.2, 4. ],\n",
       "       [6.1, 2.9, 4.7],\n",
       "       [5.6, 2.9, 3.6],\n",
       "       [6.7, 3.1, 4.4],\n",
       "       [5.6, 3. , 4.5],\n",
       "       [5.8, 2.7, 4.1],\n",
       "       [6.2, 2.2, 4.5],\n",
       "       [5.6, 2.5, 3.9],\n",
       "       [5.9, 3.2, 4.8],\n",
       "       [6.1, 2.8, 4. ],\n",
       "       [6.3, 2.5, 4.9],\n",
       "       [6.1, 2.8, 4.7],\n",
       "       [6.4, 2.9, 4.3],\n",
       "       [6.6, 3. , 4.4],\n",
       "       [6.8, 2.8, 4.8],\n",
       "       [6.7, 3. , 5. ],\n",
       "       [6. , 2.9, 4.5],\n",
       "       [5.7, 2.6, 3.5],\n",
       "       [5.5, 2.4, 3.8],\n",
       "       [5.5, 2.4, 3.7],\n",
       "       [5.8, 2.7, 3.9],\n",
       "       [6. , 2.7, 5.1],\n",
       "       [5.4, 3. , 4.5],\n",
       "       [6. , 3.4, 4.5],\n",
       "       [6.7, 3.1, 4.7],\n",
       "       [6.3, 2.3, 4.4],\n",
       "       [5.6, 3. , 4.1],\n",
       "       [5.5, 2.5, 4. ],\n",
       "       [5.5, 2.6, 4.4],\n",
       "       [6.1, 3. , 4.6],\n",
       "       [5.8, 2.6, 4. ],\n",
       "       [5. , 2.3, 3.3],\n",
       "       [5.6, 2.7, 4.2],\n",
       "       [5.7, 3. , 4.2],\n",
       "       [5.7, 2.9, 4.2],\n",
       "       [6.2, 2.9, 4.3],\n",
       "       [5.1, 2.5, 3. ],\n",
       "       [5.7, 2.8, 4.1],\n",
       "       [6.3, 3.3, 6. ],\n",
       "       [5.8, 2.7, 5.1],\n",
       "       [7.1, 3. , 5.9],\n",
       "       [6.3, 2.9, 5.6],\n",
       "       [6.5, 3. , 5.8],\n",
       "       [7.6, 3. , 6.6],\n",
       "       [4.9, 2.5, 4.5],\n",
       "       [7.3, 2.9, 6.3],\n",
       "       [6.7, 2.5, 5.8],\n",
       "       [7.2, 3.6, 6.1],\n",
       "       [6.5, 3.2, 5.1],\n",
       "       [6.4, 2.7, 5.3],\n",
       "       [6.8, 3. , 5.5],\n",
       "       [5.7, 2.5, 5. ],\n",
       "       [5.8, 2.8, 5.1],\n",
       "       [6.4, 3.2, 5.3],\n",
       "       [6.5, 3. , 5.5],\n",
       "       [7.7, 3.8, 6.7],\n",
       "       [7.7, 2.6, 6.9],\n",
       "       [6. , 2.2, 5. ],\n",
       "       [6.9, 3.2, 5.7],\n",
       "       [5.6, 2.8, 4.9],\n",
       "       [7.7, 2.8, 6.7],\n",
       "       [6.3, 2.7, 4.9],\n",
       "       [6.7, 3.3, 5.7],\n",
       "       [7.2, 3.2, 6. ],\n",
       "       [6.2, 2.8, 4.8],\n",
       "       [6.1, 3. , 4.9],\n",
       "       [6.4, 2.8, 5.6],\n",
       "       [7.2, 3. , 5.8],\n",
       "       [7.4, 2.8, 6.1],\n",
       "       [7.9, 3.8, 6.4],\n",
       "       [6.4, 2.8, 5.6],\n",
       "       [6.3, 2.8, 5.1],\n",
       "       [6.1, 2.6, 5.6],\n",
       "       [7.7, 3. , 6.1],\n",
       "       [6.3, 3.4, 5.6],\n",
       "       [6.4, 3.1, 5.5],\n",
       "       [6. , 3. , 4.8],\n",
       "       [6.9, 3.1, 5.4],\n",
       "       [6.7, 3.1, 5.6],\n",
       "       [6.9, 3.1, 5.1],\n",
       "       [5.8, 2.7, 5.1],\n",
       "       [6.8, 3.2, 5.9],\n",
       "       [6.7, 3.3, 5.7],\n",
       "       [6.7, 3. , 5.2],\n",
       "       [6.3, 2.5, 5. ],\n",
       "       [6.5, 3. , 5.2],\n",
       "       [6.2, 3.4, 5.4],\n",
       "       [5.9, 3. , 5.1]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#基于惩罚项的特征选择法\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "#带L1惩罚项的逻辑回归作为基模型的特征选择 \n",
    "SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1)).fit_transform(iris.data, iris.target)\n",
    "# 这里的惩罚项是L1,别看做是11，这里L是小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4],\n",
       "       [4.9, 3. , 1.4],\n",
       "       [4.7, 3.2, 1.3],\n",
       "       [4.6, 3.1, 1.5],\n",
       "       [5. , 3.6, 1.4],\n",
       "       [5.4, 3.9, 1.7],\n",
       "       [4.6, 3.4, 1.4],\n",
       "       [5. , 3.4, 1.5],\n",
       "       [4.4, 2.9, 1.4],\n",
       "       [4.9, 3.1, 1.5]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 例子，这里用支持向量机了 --- \n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "iris = load_iris() \n",
    "X, y = iris.data, iris.target \n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X,y) \n",
    "# 这里的惩罚项是L1,别看做是11，这里L是小写 \n",
    "model = SelectFromModel(lsvc, prefit=True) \n",
    "X_new = model.transform(X) \n",
    "X_new[:10,:] # 前10行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#基于树模型的特征选择法\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "#GBDT作为基模型的特征选择 \n",
    "SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.13402564, 0.02702027, 0.40977221, 0.42918188])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 例子：这里用了随机森林了 --- \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_   # 显示每一个特征的重要性指标，越大说明越重要，可以看出，第三第四两个特征比较重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降维\n",
    "\n",
    "当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。\n",
    "\n",
    "常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有：\n",
    "\n",
    "- 主成分分析法（PCA）\n",
    "- 线性判别分析（LDA），线性判别分析本身也是一个分类模型。\n",
    "\n",
    "PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68412563,  0.31939725],\n",
       "       [-2.71414169, -0.17700123],\n",
       "       [-2.88899057, -0.14494943],\n",
       "       [-2.74534286, -0.31829898],\n",
       "       [-2.72871654,  0.32675451],\n",
       "       [-2.28085963,  0.74133045],\n",
       "       [-2.82053775, -0.08946138],\n",
       "       [-2.62614497,  0.16338496],\n",
       "       [-2.88638273, -0.57831175],\n",
       "       [-2.6727558 , -0.11377425],\n",
       "       [-2.50694709,  0.6450689 ],\n",
       "       [-2.61275523,  0.01472994],\n",
       "       [-2.78610927, -0.235112  ],\n",
       "       [-3.22380374, -0.51139459],\n",
       "       [-2.64475039,  1.17876464],\n",
       "       [-2.38603903,  1.33806233],\n",
       "       [-2.62352788,  0.81067951],\n",
       "       [-2.64829671,  0.31184914],\n",
       "       [-2.19982032,  0.87283904],\n",
       "       [-2.5879864 ,  0.51356031],\n",
       "       [-2.31025622,  0.39134594],\n",
       "       [-2.54370523,  0.43299606],\n",
       "       [-3.21593942,  0.13346807],\n",
       "       [-2.30273318,  0.09870885],\n",
       "       [-2.35575405, -0.03728186],\n",
       "       [-2.50666891, -0.14601688],\n",
       "       [-2.46882007,  0.13095149],\n",
       "       [-2.56231991,  0.36771886],\n",
       "       [-2.63953472,  0.31203998],\n",
       "       [-2.63198939, -0.19696122],\n",
       "       [-2.58739848, -0.20431849],\n",
       "       [-2.4099325 ,  0.41092426],\n",
       "       [-2.64886233,  0.81336382],\n",
       "       [-2.59873675,  1.09314576],\n",
       "       [-2.63692688, -0.12132235],\n",
       "       [-2.86624165,  0.06936447],\n",
       "       [-2.62523805,  0.59937002],\n",
       "       [-2.80068412,  0.26864374],\n",
       "       [-2.98050204, -0.48795834],\n",
       "       [-2.59000631,  0.22904384],\n",
       "       [-2.77010243,  0.26352753],\n",
       "       [-2.84936871, -0.94096057],\n",
       "       [-2.99740655, -0.34192606],\n",
       "       [-2.40561449,  0.18887143],\n",
       "       [-2.20948924,  0.43666314],\n",
       "       [-2.71445143, -0.2502082 ],\n",
       "       [-2.53814826,  0.50377114],\n",
       "       [-2.83946217, -0.22794557],\n",
       "       [-2.54308575,  0.57941002],\n",
       "       [-2.70335978,  0.10770608],\n",
       "       [ 1.28482569,  0.68516047],\n",
       "       [ 0.93248853,  0.31833364],\n",
       "       [ 1.46430232,  0.50426282],\n",
       "       [ 0.18331772, -0.82795901],\n",
       "       [ 1.08810326,  0.07459068],\n",
       "       [ 0.64166908, -0.41824687],\n",
       "       [ 1.09506066,  0.28346827],\n",
       "       [-0.74912267, -1.00489096],\n",
       "       [ 1.04413183,  0.2283619 ],\n",
       "       [-0.0087454 , -0.72308191],\n",
       "       [-0.50784088, -1.26597119],\n",
       "       [ 0.51169856, -0.10398124],\n",
       "       [ 0.26497651, -0.55003646],\n",
       "       [ 0.98493451, -0.12481785],\n",
       "       [-0.17392537, -0.25485421],\n",
       "       [ 0.92786078,  0.46717949],\n",
       "       [ 0.66028376, -0.35296967],\n",
       "       [ 0.23610499, -0.33361077],\n",
       "       [ 0.94473373, -0.54314555],\n",
       "       [ 0.04522698, -0.58383438],\n",
       "       [ 1.11628318, -0.08461685],\n",
       "       [ 0.35788842, -0.06892503],\n",
       "       [ 1.29818388, -0.32778731],\n",
       "       [ 0.92172892, -0.18273779],\n",
       "       [ 0.71485333,  0.14905594],\n",
       "       [ 0.90017437,  0.32850447],\n",
       "       [ 1.33202444,  0.24444088],\n",
       "       [ 1.55780216,  0.26749545],\n",
       "       [ 0.81329065, -0.1633503 ],\n",
       "       [-0.30558378, -0.36826219],\n",
       "       [-0.06812649, -0.70517213],\n",
       "       [-0.18962247, -0.68028676],\n",
       "       [ 0.13642871, -0.31403244],\n",
       "       [ 1.38002644, -0.42095429],\n",
       "       [ 0.58800644, -0.48428742],\n",
       "       [ 0.80685831,  0.19418231],\n",
       "       [ 1.22069088,  0.40761959],\n",
       "       [ 0.81509524, -0.37203706],\n",
       "       [ 0.24595768, -0.2685244 ],\n",
       "       [ 0.16641322, -0.68192672],\n",
       "       [ 0.46480029, -0.67071154],\n",
       "       [ 0.8908152 , -0.03446444],\n",
       "       [ 0.23054802, -0.40438585],\n",
       "       [-0.70453176, -1.01224823],\n",
       "       [ 0.35698149, -0.50491009],\n",
       "       [ 0.33193448, -0.21265468],\n",
       "       [ 0.37621565, -0.29321893],\n",
       "       [ 0.64257601,  0.01773819],\n",
       "       [-0.90646986, -0.75609337],\n",
       "       [ 0.29900084, -0.34889781],\n",
       "       [ 2.53119273, -0.00984911],\n",
       "       [ 1.41523588, -0.57491635],\n",
       "       [ 2.61667602,  0.34390315],\n",
       "       [ 1.97153105, -0.1797279 ],\n",
       "       [ 2.35000592, -0.04026095],\n",
       "       [ 3.39703874,  0.55083667],\n",
       "       [ 0.52123224, -1.19275873],\n",
       "       [ 2.93258707,  0.3555    ],\n",
       "       [ 2.32122882, -0.2438315 ],\n",
       "       [ 2.91675097,  0.78279195],\n",
       "       [ 1.66177415,  0.24222841],\n",
       "       [ 1.80340195, -0.21563762],\n",
       "       [ 2.1655918 ,  0.21627559],\n",
       "       [ 1.34616358, -0.77681835],\n",
       "       [ 1.58592822, -0.53964071],\n",
       "       [ 1.90445637,  0.11925069],\n",
       "       [ 1.94968906,  0.04194326],\n",
       "       [ 3.48705536,  1.17573933],\n",
       "       [ 3.79564542,  0.25732297],\n",
       "       [ 1.30079171, -0.76114964],\n",
       "       [ 2.42781791,  0.37819601],\n",
       "       [ 1.19900111, -0.60609153],\n",
       "       [ 3.49992004,  0.4606741 ],\n",
       "       [ 1.38876613, -0.20439933],\n",
       "       [ 2.2754305 ,  0.33499061],\n",
       "       [ 2.61409047,  0.56090136],\n",
       "       [ 1.25850816, -0.17970479],\n",
       "       [ 1.29113206, -0.11666865],\n",
       "       [ 2.12360872, -0.20972948],\n",
       "       [ 2.38800302,  0.4646398 ],\n",
       "       [ 2.84167278,  0.37526917],\n",
       "       [ 3.23067366,  1.37416509],\n",
       "       [ 2.15943764, -0.21727758],\n",
       "       [ 1.44416124, -0.14341341],\n",
       "       [ 1.78129481, -0.49990168],\n",
       "       [ 3.07649993,  0.68808568],\n",
       "       [ 2.14424331,  0.1400642 ],\n",
       "       [ 1.90509815,  0.04930053],\n",
       "       [ 1.16932634, -0.16499026],\n",
       "       [ 2.10761114,  0.37228787],\n",
       "       [ 2.31415471,  0.18365128],\n",
       "       [ 1.9222678 ,  0.40920347],\n",
       "       [ 1.41523588, -0.57491635],\n",
       "       [ 2.56301338,  0.2778626 ],\n",
       "       [ 2.41874618,  0.3047982 ],\n",
       "       [ 1.94410979,  0.1875323 ],\n",
       "       [ 1.52716661, -0.37531698],\n",
       "       [ 1.76434572,  0.07885885],\n",
       "       [ 1.90094161,  0.11662796],\n",
       "       [ 1.39018886, -0.28266094]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#主成分分析法（PCA）\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#主成分分析法，返回降维后的数据\n",
    "#参数n_components为主成分数目\n",
    "PCA(n_components=2).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11a833860>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# --- 例子 --- \n",
    "from sklearn.decomposition import PCA,KernelPCA \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "category = pd.Categorical(iris.target) # 将标签进行量化，就是说本来都是字符串啊，但是最后计算的时候都需要量化成1，2，3类等 \n",
    "pca_2c = PCA(n_components=2) # 使用PCA降到2维 \n",
    "#pca_2c = KernelPCA(n_components=2) \n",
    "\n",
    "x_pca_2c = pca_2c.fit_transform(iris.data) \n",
    "x_pca_2c.shape \n",
    "plt.scatter(x_pca_2c[:,0],x_pca_2c[:,1],c=category.codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.06179978e+00,  3.00420621e-01],\n",
       "       [ 7.12868772e+00, -7.86660426e-01],\n",
       "       [ 7.48982797e+00, -2.65384488e-01],\n",
       "       [ 6.81320057e+00, -6.70631068e-01],\n",
       "       [ 8.13230933e+00,  5.14462530e-01],\n",
       "       [ 7.70194674e+00,  1.46172097e+00],\n",
       "       [ 7.21261762e+00,  3.55836209e-01],\n",
       "       [ 7.60529355e+00, -1.16338380e-02],\n",
       "       [ 6.56055159e+00, -1.01516362e+00],\n",
       "       [ 7.34305989e+00, -9.47319209e-01],\n",
       "       [ 8.39738652e+00,  6.47363392e-01],\n",
       "       [ 7.21929685e+00, -1.09646389e-01],\n",
       "       [ 7.32679599e+00, -1.07298943e+00],\n",
       "       [ 7.57247066e+00, -8.05464137e-01],\n",
       "       [ 9.84984300e+00,  1.58593698e+00],\n",
       "       [ 9.15823890e+00,  2.73759647e+00],\n",
       "       [ 8.58243141e+00,  1.83448945e+00],\n",
       "       [ 7.78075375e+00,  5.84339407e-01],\n",
       "       [ 8.07835876e+00,  9.68580703e-01],\n",
       "       [ 8.02097451e+00,  1.14050366e+00],\n",
       "       [ 7.49680227e+00, -1.88377220e-01],\n",
       "       [ 7.58648117e+00,  1.20797032e+00],\n",
       "       [ 8.68104293e+00,  8.77590154e-01],\n",
       "       [ 6.25140358e+00,  4.39696367e-01],\n",
       "       [ 6.55893336e+00, -3.89222752e-01],\n",
       "       [ 6.77138315e+00, -9.70634453e-01],\n",
       "       [ 6.82308032e+00,  4.63011612e-01],\n",
       "       [ 7.92461638e+00,  2.09638715e-01],\n",
       "       [ 7.99129024e+00,  8.63787128e-02],\n",
       "       [ 6.82946447e+00, -5.44960851e-01],\n",
       "       [ 6.75895493e+00, -7.59002759e-01],\n",
       "       [ 7.37495254e+00,  5.65844592e-01],\n",
       "       [ 9.12634625e+00,  1.22443267e+00],\n",
       "       [ 9.46768199e+00,  1.82522635e+00],\n",
       "       [ 7.06201386e+00, -6.63400423e-01],\n",
       "       [ 7.95876243e+00, -1.64961722e-01],\n",
       "       [ 8.61367201e+00,  4.03253602e-01],\n",
       "       [ 8.33041759e+00,  2.28133530e-01],\n",
       "       [ 6.93412007e+00, -7.05519379e-01],\n",
       "       [ 7.68823131e+00, -9.22362309e-03],\n",
       "       [ 7.91793715e+00,  6.75121313e-01],\n",
       "       [ 5.66188065e+00, -1.93435524e+00],\n",
       "       [ 7.24101468e+00, -2.72615132e-01],\n",
       "       [ 6.41443556e+00,  1.24730131e+00],\n",
       "       [ 6.85944381e+00,  1.05165396e+00],\n",
       "       [ 6.76470393e+00, -5.05151855e-01],\n",
       "       [ 8.08189937e+00,  7.63392750e-01],\n",
       "       [ 7.18676904e+00, -3.60986823e-01],\n",
       "       [ 8.31444876e+00,  6.44953177e-01],\n",
       "       [ 7.67196741e+00, -1.34893840e-01],\n",
       "       [-1.45927545e+00,  2.85437643e-02],\n",
       "       [-1.79770574e+00,  4.84385502e-01],\n",
       "       [-2.41694888e+00, -9.27840307e-02],\n",
       "       [-2.26247349e+00, -1.58725251e+00],\n",
       "       [-2.54867836e+00, -4.72204898e-01],\n",
       "       [-2.42996725e+00, -9.66132066e-01],\n",
       "       [-2.44848456e+00,  7.95961954e-01],\n",
       "       [-2.22666513e-01, -1.58467318e+00],\n",
       "       [-1.75020123e+00, -8.21180130e-01],\n",
       "       [-1.95842242e+00, -3.51563753e-01],\n",
       "       [-1.19376031e+00, -2.63445570e+00],\n",
       "       [-1.85892567e+00,  3.19006544e-01],\n",
       "       [-1.15809388e+00, -2.64340991e+00],\n",
       "       [-2.66605725e+00, -6.42504540e-01],\n",
       "       [-3.78367218e-01,  8.66389312e-02],\n",
       "       [-1.20117255e+00,  8.44373592e-02],\n",
       "       [-2.76810246e+00,  3.21995363e-02],\n",
       "       [-7.76854039e-01, -1.65916185e+00],\n",
       "       [-3.49805433e+00, -1.68495616e+00],\n",
       "       [-1.09042788e+00, -1.62658350e+00],\n",
       "       [-3.71589615e+00,  1.04451442e+00],\n",
       "       [-9.97610366e-01, -4.90530602e-01],\n",
       "       [-3.83525931e+00, -1.40595806e+00],\n",
       "       [-2.25741249e+00, -1.42679423e+00],\n",
       "       [-1.25571326e+00, -5.46424197e-01],\n",
       "       [-1.43755762e+00, -1.34424979e-01],\n",
       "       [-2.45906137e+00, -9.35277280e-01],\n",
       "       [-3.51848495e+00,  1.60588866e-01],\n",
       "       [-2.58979871e+00, -1.74611728e-01],\n",
       "       [ 3.07487884e-01, -1.31887146e+00],\n",
       "       [-1.10669179e+00, -1.75225371e+00],\n",
       "       [-6.05524589e-01, -1.94298038e+00],\n",
       "       [-8.98703769e-01, -9.04940034e-01],\n",
       "       [-4.49846635e+00, -8.82749915e-01],\n",
       "       [-2.93397799e+00,  2.73791065e-02],\n",
       "       [-2.10360821e+00,  1.19156767e+00],\n",
       "       [-2.14258208e+00,  8.87797815e-02],\n",
       "       [-2.47945603e+00, -1.94073927e+00],\n",
       "       [-1.32552574e+00, -1.62869550e-01],\n",
       "       [-1.95557887e+00, -1.15434826e+00],\n",
       "       [-2.40157020e+00, -1.59458341e+00],\n",
       "       [-2.29248878e+00, -3.32860296e-01],\n",
       "       [-1.27227224e+00, -1.21458428e+00],\n",
       "       [-2.93176055e-01, -1.79871509e+00],\n",
       "       [-2.00598883e+00, -9.05418042e-01],\n",
       "       [-1.18166311e+00, -5.37570242e-01],\n",
       "       [-1.61615645e+00, -4.70103580e-01],\n",
       "       [-1.42158879e+00, -5.51244626e-01],\n",
       "       [ 4.75973788e-01, -7.99905482e-01],\n",
       "       [-1.54948259e+00, -5.93363582e-01],\n",
       "       [-7.83947399e+00,  2.13973345e+00],\n",
       "       [-5.50747997e+00, -3.58139892e-02],\n",
       "       [-6.29200850e+00,  4.67175777e-01],\n",
       "       [-5.60545633e+00, -3.40738058e-01],\n",
       "       [-6.85055995e+00,  8.29825394e-01],\n",
       "       [-7.41816784e+00, -1.73117995e-01],\n",
       "       [-4.67799541e+00, -4.99095015e-01],\n",
       "       [-6.31692685e+00, -9.68980756e-01],\n",
       "       [-6.32773684e+00, -1.38328993e+00],\n",
       "       [-6.85281335e+00,  2.71758963e+00],\n",
       "       [-4.44072512e+00,  1.34723692e+00],\n",
       "       [-5.45009572e+00, -2.07736942e-01],\n",
       "       [-5.66033713e+00,  8.32713617e-01],\n",
       "       [-5.95823722e+00, -9.40175447e-02],\n",
       "       [-6.75926282e+00,  1.60023206e+00],\n",
       "       [-5.80704331e+00,  2.01019882e+00],\n",
       "       [-5.06601233e+00, -2.62733839e-02],\n",
       "       [-6.60881882e+00,  1.75163587e+00],\n",
       "       [-9.17147486e+00, -7.48255067e-01],\n",
       "       [-4.76453569e+00, -2.15573720e+00],\n",
       "       [-6.27283915e+00,  1.64948141e+00],\n",
       "       [-5.36071189e+00,  6.46120732e-01],\n",
       "       [-7.58119982e+00, -9.80722934e-01],\n",
       "       [-4.37150279e+00, -1.21297458e-01],\n",
       "       [-5.72317531e+00,  1.29327553e+00],\n",
       "       [-5.27915920e+00, -4.24582377e-02],\n",
       "       [-4.08087208e+00,  1.85936572e-01],\n",
       "       [-4.07703640e+00,  5.23238483e-01],\n",
       "       [-6.51910397e+00,  2.96976389e-01],\n",
       "       [-4.58371942e+00, -8.56815813e-01],\n",
       "       [-6.22824009e+00, -7.12719638e-01],\n",
       "       [-5.22048773e+00,  1.46819509e+00],\n",
       "       [-6.80015000e+00,  5.80895175e-01],\n",
       "       [-3.81515972e+00, -9.42985932e-01],\n",
       "       [-5.10748966e+00, -2.13059000e+00],\n",
       "       [-6.79671631e+00,  8.63090395e-01],\n",
       "       [-6.52449599e+00,  2.44503527e+00],\n",
       "       [-4.99550279e+00,  1.87768525e-01],\n",
       "       [-3.93985300e+00,  6.14020389e-01],\n",
       "       [-5.20383090e+00,  1.14476808e+00],\n",
       "       [-6.65308685e+00,  1.80531976e+00],\n",
       "       [-5.10555946e+00,  1.99218201e+00],\n",
       "       [-5.50747997e+00, -3.58139892e-02],\n",
       "       [-6.79601924e+00,  1.46068695e+00],\n",
       "       [-6.84735943e+00,  2.42895067e+00],\n",
       "       [-5.64500346e+00,  1.67771734e+00],\n",
       "       [-5.17956460e+00, -3.63475041e-01],\n",
       "       [-4.96774090e+00,  8.21140550e-01],\n",
       "       [-5.88614539e+00,  2.34509051e+00],\n",
       "       [-4.68315426e+00,  3.32033811e-01]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#线性判别分析法（LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#线性判别分析法，返回降维后的数据\n",
    "#参数n_components为降维后的维数\n",
    "LinearDiscriminantAnalysis(n_components=2).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
